{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainmodel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVVOEcwE8sc",
        "colab_type": "code",
        "outputId": "d2a4fbc4-5698-4247-d6eb-614b33ee7a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 15422135494866300524, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 12363721239630301053\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 5427981714306306321\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15701463552\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 17410009793484925684\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi_Bxx73FKN0",
        "colab_type": "code",
        "outputId": "f10c262a-d400-439d-ee61-067bfa85d838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!git clone https://github.com/giaivi1403/LibaryMe.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LibaryMe'...\n",
            "remote: Enumerating objects: 32280, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/32280)\u001b[K\rremote: Counting objects:   1% (323/32280)\u001b[K\rremote: Counting objects:   2% (646/32280)\u001b[K\rremote: Counting objects:   3% (969/32280)\u001b[K\rremote: Counting objects:   4% (1292/32280)\u001b[K\rremote: Counting objects:   5% (1614/32280)\u001b[K\rremote: Counting objects:   6% (1937/32280)\u001b[K\rremote: Counting objects:   7% (2260/32280)\u001b[K\rremote: Counting objects:   8% (2583/32280)\u001b[K\rremote: Counting objects:   9% (2906/32280)\u001b[K\rremote: Counting objects:  10% (3228/32280)\u001b[K\rremote: Counting objects:  11% (3551/32280)\u001b[K\rremote: Counting objects:  12% (3874/32280)\u001b[K\rremote: Counting objects:  13% (4197/32280)\u001b[K\rremote: Counting objects:  14% (4520/32280)\u001b[K\rremote: Counting objects:  15% (4842/32280)\u001b[K\rremote: Counting objects:  16% (5165/32280)\u001b[K\rremote: Counting objects:  17% (5488/32280)\u001b[K\rremote: Counting objects:  18% (5811/32280)\u001b[K\rremote: Counting objects:  19% (6134/32280)\u001b[K\rremote: Counting objects:  20% (6456/32280)\u001b[K\rremote: Counting objects:  21% (6779/32280)\u001b[K\rremote: Counting objects:  22% (7102/32280)\u001b[K\rremote: Counting objects:  23% (7425/32280)\u001b[K\rremote: Counting objects:  24% (7748/32280)\u001b[K\rremote: Counting objects:  25% (8070/32280)\u001b[K\rremote: Counting objects:  26% (8393/32280)\u001b[K\rremote: Counting objects:  27% (8716/32280)\u001b[K\rremote: Counting objects:  28% (9039/32280)\u001b[K\rremote: Counting objects:  29% (9362/32280)\u001b[K\rremote: Counting objects:  30% (9684/32280)\u001b[K\rremote: Counting objects:  31% (10007/32280)\u001b[K\rremote: Counting objects:  32% (10330/32280)\u001b[K\rremote: Counting objects:  33% (10653/32280)\u001b[K\rremote: Counting objects:  34% (10976/32280)\u001b[K\rremote: Counting objects:  35% (11298/32280)\u001b[K\rremote: Counting objects:  36% (11621/32280)\u001b[K\rremote: Counting objects:  37% (11944/32280)\u001b[K\rremote: Counting objects:  38% (12267/32280)\u001b[K\rremote: Counting objects:  39% (12590/32280)\u001b[K\rremote: Counting objects:  40% (12912/32280)\u001b[K\rremote: Counting objects:  41% (13235/32280)\u001b[K\rremote: Counting objects:  42% (13558/32280)\u001b[K\rremote: Counting objects:  43% (13881/32280)\u001b[K\rremote: Counting objects:  44% (14204/32280)\u001b[K\rremote: Counting objects:  45% (14526/32280)\u001b[K\rremote: Counting objects:  46% (14849/32280)\u001b[K\rremote: Counting objects:  47% (15172/32280)\u001b[K\rremote: Counting objects:  48% (15495/32280)\u001b[K\rremote: Counting objects:  49% (15818/32280)\u001b[K\rremote: Counting objects:  50% (16140/32280)\u001b[K\rremote: Counting objects:  51% (16463/32280)\u001b[K\rremote: Counting objects:  52% (16786/32280)\u001b[K\rremote: Counting objects:  53% (17109/32280)\u001b[K\rremote: Counting objects:  54% (17432/32280)\u001b[K\rremote: Counting objects:  55% (17754/32280)\u001b[K\rremote: Counting objects:  56% (18077/32280)\u001b[K\rremote: Counting objects:  57% (18400/32280)\u001b[K\rremote: Counting objects:  58% (18723/32280)\u001b[K\rremote: Counting objects:  59% (19046/32280)\u001b[K\rremote: Counting objects:  60% (19368/32280)\u001b[K\rremote: Counting objects:  61% (19691/32280)\u001b[K\rremote: Counting objects:  62% (20014/32280)\u001b[K\rremote: Counting objects:  63% (20337/32280)\u001b[K\rremote: Counting objects:  64% (20660/32280)\u001b[K\rremote: Counting objects:  65% (20982/32280)\u001b[K\rremote: Counting objects:  66% (21305/32280)\u001b[K\rremote: Counting objects:  67% (21628/32280)\u001b[K\rremote: Counting objects:  68% (21951/32280)\u001b[K\rremote: Counting objects:  69% (22274/32280)\u001b[K\rremote: Counting objects:  70% (22596/32280)\u001b[K\rremote: Counting objects:  71% (22919/32280)\u001b[K\rremote: Counting objects:  72% (23242/32280)\u001b[K\rremote: Counting objects:  73% (23565/32280)\u001b[K\rremote: Counting objects:  74% (23888/32280)\u001b[K\rremote: Counting objects:  75% (24210/32280)\u001b[K\rremote: Counting objects:  76% (24533/32280)\u001b[K\rremote: Counting objects:  77% (24856/32280)\u001b[K\rremote: Counting objects:  78% (25179/32280)\u001b[K\rremote: Counting objects:  79% (25502/32280)\u001b[K\rremote: Counting objects:  80% (25824/32280)\u001b[K\rremote: Counting objects:  81% (26147/32280)\u001b[K\rremote: Counting objects:  82% (26470/32280)\u001b[K\rremote: Counting objects:  83% (26793/32280)\u001b[K\rremote: Counting objects:  84% (27116/32280)\u001b[K\rremote: Counting objects:  85% (27438/32280)\u001b[K\rremote: Counting objects:  86% (27761/32280)\u001b[K\rremote: Counting objects:  87% (28084/32280)\u001b[K\rremote: Counting objects:  88% (28407/32280)\u001b[K\rremote: Counting objects:  89% (28730/32280)\u001b[K\rremote: Counting objects:  90% (29052/32280)\u001b[K\rremote: Counting objects:  91% (29375/32280)\u001b[K\rremote: Counting objects:  92% (29698/32280)\u001b[K\rremote: Counting objects:  93% (30021/32280)\u001b[K\rremote: Counting objects:  94% (30344/32280)\u001b[K\rremote: Counting objects:  95% (30666/32280)\u001b[K\rremote: Counting objects:  96% (30989/32280)\u001b[K\rremote: Counting objects:  97% (31312/32280)\u001b[K\rremote: Counting objects:  98% (31635/32280)\u001b[K\rremote: Counting objects:  99% (31958/32280)\u001b[K\rremote: Counting objects: 100% (32280/32280)\u001b[K\rremote: Counting objects: 100% (32280/32280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32272/32272), done.\u001b[K\n",
            "remote: Total 35672 (delta 5), reused 32277 (delta 4), pack-reused 3392\u001b[K\n",
            "Receiving objects: 100% (35672/35672), 771.88 MiB | 34.40 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Checking out files: 100% (35722/35722), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W_TCBGBFWAk",
        "colab_type": "code",
        "outputId": "92515cfd-2d20-4460-dcad-44070e7cd7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd LibaryMe"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LibaryMe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8G2UzVOFYBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cnn.MiniVGG import MiniVGGnet\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiNuLZyIFmzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b904c47f-ec3c-4e11-8f47-99254b77b903"
      },
      "source": [
        "print(\"[INFO] Loading CIFAR10...\")\n",
        "(trainX,trainY), (testX,testY) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float\")/255.0\n",
        "testX = testX.astype(\"float\")/255.0\n",
        "\n",
        "label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "opt = SGD(lr = 0.01 , momentum = 0.9 , nesterov = True, decay = 0.01/40)\n",
        "model = MiniVGGnet.MINIVGGNET.build(height = 32 , width = 32, depth = 3, classes = 10)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "fname = \"best-weight-traincifar10.hdf5\"\n",
        "checkpoint = ModelCheckpoint(fname,monitor =\"val_loss\" , save_best_only = True , verbose = 1)\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "print(\"[INFO] training ...\")\n",
        "history = model.fit(trainX,trainY, validation_data =(testX,testY), batch_size = 128, epochs = 40, verbose = 1, callbacks = callbacks)\n",
        "\n",
        "print(\"[INFO] Predicting...\")\n",
        "preds = model.predict(testX,batch_size = 128)\n",
        "\n",
        "print(classification_report(testY.argmax(axis =1) , preds.argmax(axis = 1), target_names= label_names))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading CIFAR10...\n",
            "[INFO] training ...\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 8s 151us/step - loss: 1.7636 - accuracy: 0.4015 - val_loss: 1.5462 - val_accuracy: 0.4430\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.54615, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 1.3243 - accuracy: 0.5289 - val_loss: 1.2276 - val_accuracy: 0.5593\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.54615 to 1.22757, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 1.1478 - accuracy: 0.5903 - val_loss: 1.1493 - val_accuracy: 0.5900\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22757 to 1.14929, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 1.0276 - accuracy: 0.6355 - val_loss: 0.9930 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.14929 to 0.99299, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.9370 - accuracy: 0.6696 - val_loss: 0.8702 - val_accuracy: 0.6926\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.99299 to 0.87024, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.8721 - accuracy: 0.6917 - val_loss: 0.8078 - val_accuracy: 0.7211\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.87024 to 0.80780, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 7s 142us/step - loss: 0.8161 - accuracy: 0.7111 - val_loss: 0.9070 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.80780\n",
            "Epoch 8/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.7670 - accuracy: 0.7279 - val_loss: 0.8097 - val_accuracy: 0.7151\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.80780\n",
            "Epoch 9/40\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.7264 - accuracy: 0.7427 - val_loss: 0.7109 - val_accuracy: 0.7510\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.80780 to 0.71088, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.6883 - accuracy: 0.7572 - val_loss: 0.8314 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.71088\n",
            "Epoch 11/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.6637 - accuracy: 0.7640 - val_loss: 0.6926 - val_accuracy: 0.7633\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.71088 to 0.69256, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 12/40\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.6379 - accuracy: 0.7739 - val_loss: 0.7349 - val_accuracy: 0.7531\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.69256\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.6130 - accuracy: 0.7821 - val_loss: 0.7211 - val_accuracy: 0.7587\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.69256\n",
            "Epoch 14/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.5935 - accuracy: 0.7909 - val_loss: 0.6384 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.69256 to 0.63844, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 15/40\n",
            "50000/50000 [==============================] - 7s 142us/step - loss: 0.5696 - accuracy: 0.7990 - val_loss: 0.6416 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.63844\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.5478 - accuracy: 0.8054 - val_loss: 0.7389 - val_accuracy: 0.7527\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.63844\n",
            "Epoch 17/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.5351 - accuracy: 0.8088 - val_loss: 0.6461 - val_accuracy: 0.7802\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.63844\n",
            "Epoch 18/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.5226 - accuracy: 0.8142 - val_loss: 0.6472 - val_accuracy: 0.7848\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.63844\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.5033 - accuracy: 0.8207 - val_loss: 0.6503 - val_accuracy: 0.7805\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.63844\n",
            "Epoch 20/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.4909 - accuracy: 0.8247 - val_loss: 0.6506 - val_accuracy: 0.7840\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.63844\n",
            "Epoch 21/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.4670 - accuracy: 0.8332 - val_loss: 0.6498 - val_accuracy: 0.7855\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.63844\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.4585 - accuracy: 0.8365 - val_loss: 0.6058 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.63844 to 0.60585, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 23/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.4424 - accuracy: 0.8408 - val_loss: 0.6257 - val_accuracy: 0.7922\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.60585\n",
            "Epoch 24/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.4355 - accuracy: 0.8440 - val_loss: 0.7461 - val_accuracy: 0.7633\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.60585\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.4281 - accuracy: 0.8443 - val_loss: 0.6309 - val_accuracy: 0.7894\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.60585\n",
            "Epoch 26/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.4132 - accuracy: 0.8523 - val_loss: 0.6071 - val_accuracy: 0.7982\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.60585\n",
            "Epoch 27/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.4096 - accuracy: 0.8532 - val_loss: 0.6345 - val_accuracy: 0.7891\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.60585\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3969 - accuracy: 0.8572 - val_loss: 0.6265 - val_accuracy: 0.7946\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.60585\n",
            "Epoch 29/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3842 - accuracy: 0.8625 - val_loss: 0.6493 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.60585\n",
            "Epoch 30/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3712 - accuracy: 0.8664 - val_loss: 0.6001 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.60585 to 0.60005, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3606 - accuracy: 0.8687 - val_loss: 0.6278 - val_accuracy: 0.7952\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.60005\n",
            "Epoch 32/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3639 - accuracy: 0.8698 - val_loss: 0.6297 - val_accuracy: 0.7978\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.60005\n",
            "Epoch 33/40\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.3515 - accuracy: 0.8740 - val_loss: 0.6754 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.60005\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.3430 - accuracy: 0.8764 - val_loss: 0.6001 - val_accuracy: 0.8060\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.60005\n",
            "Epoch 35/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3387 - accuracy: 0.8779 - val_loss: 0.6536 - val_accuracy: 0.7952\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.60005\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3279 - accuracy: 0.8818 - val_loss: 0.5963 - val_accuracy: 0.8056\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.60005 to 0.59626, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3228 - accuracy: 0.8849 - val_loss: 0.6119 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.59626\n",
            "Epoch 38/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3180 - accuracy: 0.8868 - val_loss: 0.6184 - val_accuracy: 0.8032\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.59626\n",
            "Epoch 39/40\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.3093 - accuracy: 0.8894 - val_loss: 0.5906 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.59626 to 0.59063, saving model to best-weight-traincifar10.hdf5\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3067 - accuracy: 0.8884 - val_loss: 0.6071 - val_accuracy: 0.8044\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.59063\n",
            "[INFO] Predicting...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.86      0.78      0.82      1000\n",
            "  automobile       0.87      0.91      0.89      1000\n",
            "        bird       0.73      0.70      0.72      1000\n",
            "         cat       0.64      0.67      0.65      1000\n",
            "        deer       0.80      0.76      0.78      1000\n",
            "         dog       0.73      0.70      0.72      1000\n",
            "        frog       0.84      0.88      0.86      1000\n",
            "       horse       0.86      0.85      0.85      1000\n",
            "        ship       0.88      0.90      0.89      1000\n",
            "       truck       0.85      0.88      0.87      1000\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.80     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax6_6MDpPGLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}